{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Run to generate the folder for the Torch ImageLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find closest image to resistivity timestamp\n",
    "#def find_closest_image(ts):\n",
    "    # Given a presorted list of timestamps:  s = sorted(index)\n",
    "#    i = bisect_left(s, ts)\n",
    "#    return min(s[max(0, i-1): i+2], key=lambda t: abs(ts - t))\n",
    "\n",
    "import io\n",
    "import csv\n",
    "import shutil\n",
    "img_folder = 'data/timelapse_images_fast'\n",
    "\n",
    "with open('data/labels.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        img_name = row[1]\n",
    "        label = int(row[2]=='True')\n",
    "        month_folder = row[0][:10]\n",
    "        #print(month_folder)\n",
    "        #print(img_name,label)\n",
    "        #print(os.path.join(img_folder,month_folder,img_name))\n",
    "        shutil.copyfile(os.path.join(img_folder,month_folder,img_name),os.path.join(img_folder,str(label),img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "#from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd42c0efc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102716\n"
     ]
    }
   ],
   "source": [
    "opts = {}\n",
    "opts['epochs'] = 10\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 0.003\n",
    "opts['nr_classes'] = 2\n",
    "\n",
    "TRAIN_DATA_PATH = \"./data/binary_classification\"\n",
    "TEST_DATA_PATH = \"./test_named_cl/\"\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.CenterCrop(64),\n",
    "    #transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                     std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "print(len(train_data.imgs))\n",
    "# split into (train,val,test)\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(0.1 * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=opts['batch_size'], sampler=train_sampler,  num_workers=4)\n",
    "valid_data_loader = data.DataLoader(train_data, batch_size=opts['batch_size'], sampler=valid_sampler,  num_workers=4)\n",
    "\n",
    "#train_iter = iter(train_data_loader)\n",
    "#test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "#test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCNN(torch.nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(BinaryCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class CNN2(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=32):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        #print(self.conv4_bn)\n",
    "        self.linear = nn.Linear(d*8*4*4,2)\n",
    "        #self.conv5 = nn.Conv2d(d*8, 4, 4, 1, 0)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        #x = F.sigmoid(self.conv5(x))\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445it [03:16,  7.36it/s]\n",
      "161it [00:08, 18.83it/s]\n",
      "1445it [03:05,  7.81it/s]\n",
      "161it [00:08, 18.84it/s]\n",
      "1445it [03:04,  7.82it/s]\n",
      "161it [00:08, 18.79it/s]\n",
      "1445it [03:08,  7.66it/s]\n",
      "161it [00:08, 19.02it/s]\n",
      "1445it [03:05,  7.78it/s]\n",
      "161it [00:08, 18.51it/s]\n",
      "1445it [03:06,  7.76it/s]\n",
      "161it [00:08, 19.03it/s]\n",
      "1445it [03:04,  7.84it/s]\n",
      "161it [00:08, 19.06it/s]\n",
      "1207it [02:35,  7.51it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5c96c5681d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = CNN2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=opts['lr'])\n",
    "bins = np.array([0,91,182,273,366])\n",
    "nr_batches = len(train_data_loader)\n",
    "\n",
    "for epoch in range(opts['epochs']):  \n",
    "    running_loss = 0.0\n",
    "    for i, sample in tqdm(enumerate(train_data_loader, 0)):\n",
    "        inputs, labels = sample\n",
    "        # quantize labels to 4 bins\n",
    "        #labels_q = torch.tensor(np.digitize(labels,bins))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        # tensorboard \n",
    "        writer.add_scalar('Loss/train', loss, epoch*nr_batches + i)\n",
    "    \n",
    "    # run on test set\n",
    "    test_losses = []\n",
    "    for i, test_sample in tqdm(enumerate(valid_data_loader, 0)):\n",
    "        test_inputs, test_labels = test_sample\n",
    "        # forward\n",
    "        test_outputs = net(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_labels)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "    writer.add_scalar('Loss/test', np.mean(test_losses), epoch)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-01-01 07:00:00+00:00</th>\n",
       "      <th>20170101_070009.JPG</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 07:04:00+00:00</td>\n",
       "      <td>20170101_070409.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 07:08:00+00:00</td>\n",
       "      <td>20170101_070809.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 07:12:00+00:00</td>\n",
       "      <td>20170101_071211.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 07:16:00+00:00</td>\n",
       "      <td>20170101_071610.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 07:20:00+00:00</td>\n",
       "      <td>20170101_072011.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102710</th>\n",
       "      <td>2017-12-31 23:00:00+00:00</td>\n",
       "      <td>20171231_234008.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102711</th>\n",
       "      <td>2017-12-31 23:00:00+00:00</td>\n",
       "      <td>20171231_234407.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102712</th>\n",
       "      <td>2017-12-31 23:00:00+00:00</td>\n",
       "      <td>20171231_234807.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102713</th>\n",
       "      <td>2017-12-31 23:00:00+00:00</td>\n",
       "      <td>20171231_235207.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102714</th>\n",
       "      <td>2017-12-31 23:00:00+00:00</td>\n",
       "      <td>20171231_235607.JPG</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102715 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2017-01-01 07:00:00+00:00  20170101_070009.JPG  True\n",
       "0       2017-01-01 07:04:00+00:00  20170101_070409.JPG  True\n",
       "1       2017-01-01 07:08:00+00:00  20170101_070809.JPG  True\n",
       "2       2017-01-01 07:12:00+00:00  20170101_071211.JPG  True\n",
       "3       2017-01-01 07:16:00+00:00  20170101_071610.JPG  True\n",
       "4       2017-01-01 07:20:00+00:00  20170101_072011.JPG  True\n",
       "...                           ...                  ...   ...\n",
       "102710  2017-12-31 23:00:00+00:00  20171231_234008.JPG  True\n",
       "102711  2017-12-31 23:00:00+00:00  20171231_234407.JPG  True\n",
       "102712  2017-12-31 23:00:00+00:00  20171231_234807.JPG  True\n",
       "102713  2017-12-31 23:00:00+00:00  20171231_235207.JPG  True\n",
       "102714  2017-12-31 23:00:00+00:00  20171231_235607.JPG  True\n",
       "\n",
       "[102715 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import seaborn as sns\n",
    "#data = pd.read_csv(\"data/timeseries_derived_data_products/MH11_resistivity_rock_2017.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "data = pd.read_csv(\"data/labels.csv\") \n",
    "#pd.DataFrame.plot.line(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 2, 1, 1, 1, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([2,30,330,102,35,67,82,230])\n",
    "bins = np.array([1,90,180,270,360])\n",
    "np.histogram(labels, bins)\n",
    "np.digitize(labels,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, sample in enumerate(train_data_loader):\n",
    "    images, labels = sample\n",
    "    labels_q = np.digitize(labels,bins)\n",
    "    plt.imshow(  sample[0][0].permute(1, 2, 0)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 0\n",
    "min_val = 100\n",
    "for i, sample in tqdm(enumerate(train_data_loader, 0)):\n",
    "    max_tmp = torch.max(sample[1])\n",
    "    min_tmp = torch.min(sample[1])\n",
    "\n",
    "    if max_tmp > max_val:\n",
    "        max_val = max_tmp\n",
    "    if min_tmp < min_val:\n",
    "        min_val = min_tmp\n",
    "\n",
    "print(max_val)\n",
    "print(min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
